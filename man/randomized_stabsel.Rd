% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stability_selection.R
\name{randomized_stabsel}
\alias{randomized_stabsel}
\title{Randomized Lasso Stability Selection}
\usage{
randomized_stabsel(
  x = NULL,
  y = NULL,
  weakness = 0.8,
  cutoff = 0.8,
  PFER = 2,
  ...
)
}
\arguments{
\item{x}{the predictor matrix.}

\item{y}{the response vector.}

\item{weakness}{value between 0 and 1 (default = 0.8). 
It affects how strict the method will be in selecting predictors. The closer it is to 0, 
the more stringent the selection. A weakness value of 1 is identical to performing 
lasso stability selection (not the randomized version).}

\item{cutoff}{value between 0 and 1 (default = 0.8) which is the cutoff for the selection probability. 
Any variable with a selection probability that is higher than the set cutoff will be selected.}

\item{PFER}{integer (default = 2) representing the absolute number of false positives that we 
allow for in the final list of selected variables. For details see Meinshausen and Bühlmann (2010).}

\item{...}{additional parameters that can be passed on to \code{\link[glmnet]{glmnet}}.}
}
\value{
A \code{SummarizedExperiment} object where the rows are the 
  predictors and the columns are the different 
  regularization steps. The object consists of: \itemize{
     \item{assay}{:  \itemize{
       \item{selProb}{: the selection probabilities of the predictors 
       across the different regularization steps.}
       }
     }
     \item{metadata}{: list with: \itemize{
       \item{stabselParams}{: }
       \item{randStabselParams}{: }
       }
     }
  }
}
\description{
This function runs randomized lasso stability selection as presented by Meinshausen
  and Bühlmann (2010) and with the improved error bounds introduced by Shah and Samworth (2013). The function
  uses the \code{\link[stabs]{stabsel}} function from the \code{stabs} package, but implements the randomized lasso version.
}
\details{
Randomized lasso stability selection runs a randomized lasso regression 
  several times on subsamples of the response variable and predictor matrix. 
  N/2 elements from the response variable are randomly chosen in each regression, 
  where N is the length of the vector. The corresponsing section of the predictor matrix is
  also chosen, and the \code{\link[monaLisa]{glmnet.randomized_lasso}} function is applied. 
  Stability selection results in selection probabilities for each predictor. 
  The probability of a specific predictor is the number of
  times it was selected divided by the total number of subsamples that were done 
  (total number of times the regression was performed).

  We made use of the \code{stabs} package that implements lasso stability selection, 
  and adapted it to run randomized lasso stability selection.
}
\references{
N. Meinshausen and P. Bühlmann (2010), Stability Selection, \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, \strong{72}, 417–73. \cr
R.D. Shah and R.J. Samworth (2013), Variable Selection with Error Control: Another Look at Stability Selection, \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, \strong{75}, 55–80. \cr
B. Hofner, L. Boccuto, and M. Göker (2015), Controlling False Discoveries in High-Dimensional Situations: Boosting with Stability Selection, \emph{BMC Bioinformatics}, \strong{16} 144.
}
\seealso{
\code{\link[stabs]{stabsel}}
}
